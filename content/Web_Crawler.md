## **Web Crawler**


### Source
  * [Common Crawl](https://commoncrawl.org/): an open repository of web crawl data that can be accessed and analyzed by anyone.

### Tools
  * [Scrapy](https://github.com/scrapy/scrapy)
  * [Pyspider](https://github.com/binux/pyspider)
  * [InfoSpider](https://github.com/kangvcar/InfoSpider)

### Literatures/Books

### Awesome-crawler
  * link: https://github.com/BruceDone/awesome-crawler
  * author: Bruce Tang
  * note: a collection of awesome web crawler,spider in different languages

### examples-of-web-crawlers
  * link: https://github.com/shengqiangzhang/examples-of-web-crawlers
  * author: Shengqiang Zhang
  * note: some interesting examples of python crawlers that are friendly to beginners.

### Crack-JS
  * link: https://github.com/xianyucoder/Crack-JS
  * blog: http://xianyucoder.cn/
  * author: huangjin
  * note: Python3爬虫项目进阶实战.
  
### wechat-spider
  * link: https://github.com/striver-ing/wechat-spider
  * author: striver-ing
  * note: 开源微信爬虫：爬取公众号所有 文章、阅读量、点赞量和评论内容.

### crawlab
  * link: https://github.com/crawlab-team/crawlab
  * author: [Crawlab Team](https://github.com/crawlab-team)
  * note: 分布式爬虫管理平台，支持任何语言和框架.

### paperscraper
  * link: https://github.com/PhosphorylatedRabbits/paperscraper
  * author: PhosphorylatedRabbits
  * note: tools to scrape publication metadata from pubmed, arxiv, medrxiv and chemrxiv.
